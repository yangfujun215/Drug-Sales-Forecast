Attn_head.py
这段代码定义了一个名为Attn_head的类，它是基于PyTorch的一个深度学习模块，专门设计来处理带有注意力机制的神经网络层。这个类通过引入注意力机制学习输入特征之间的关系权重（即注意力权重），使神经网络更加关注于重要的输入特征，提高模型对数据的理解和处理能力。
文件内容概述
模块导入：文件开始部分导入了torch和torch.nn模块，表明Attn_head类依赖于PyTorch深度学习框架。
类定义：Attn_head继承自torch.nn.Module，是一个自定义的神经网络模块，旨在通过卷积层实现一个可学习的注意力机制
Attn_head功能和特点
注意力机制：该类通过注意力机制强化模型对输入特征中重要信息的关注。
参数化构造：在其构造函数中，Attn_head接受多个参数，包括输入特征的通道数(in_channel)、
输出特征的大小(out_sz)、输入系数的dropout率(in_drop)、注意力系数的dropout率(coef_drop)、激活函数(activation)以及是否使用残差连接(residual)。
网络层：Attn_head内部定义了一系列网络层，包括卷积层和激活函数，以及用于实现dropout和残差连接的组件。

grumodel.py
这段代码定义了一个名为GRUModel的Python类，它是一个基于PyTorch框架实现的神经网络模型，专门设计用于处理序列数据。这个类利用门控循环单元（GRU）来捕获序列中的时间依赖性。
文件内容概述
模块导入：文件开始部分导入了torch.nn模块，这表明GRUModel类依赖于PyTorch深度学习框架。
类定义：GRUModel继承自torch.nn.Module，是一个自定义的神经网络模型，旨在通过GRU（Gated Recurrent Unit，门控循环单元）层处理序列数据。
GRUModel功能和特点
序列数据处理：GRUModel利用GRU层来处理时间序列数据，GRU是一种循环神经网络（RNN）的变种，用于处理时间依赖性强的数据。
参数化构造：在其构造函数中，GRUModel接受多个参数，包括输入特征的维度(input_dim)、GRU隐层的大小(hidden_dim)、模型输出的特征维度(output_dim)以及GRU网络的层数(num_layers)。
网络层：GRUModel内部定义了一个GRU层，用于序列数据的特征提取和学习，以及一个全连接层，用于将GRU层的输出映射到目标输出空间。


hyperedge_attn.py
这段代码定义了一个名为hyperedge_atten的Python类，它是一个基于PyTorch框架的深度学习模块，用于实现基于注意力机制的超边（hyperedge）网络层。
文件内容概述
模块导入：文件开始部分导入了torch和torch.nn模块，以及自定义的Attn_head类，表明hyperedge_atten类依赖于PyTorch深度学习框架以及特定的注意力机制实现。
类hyperedge_atten功能和特点
超边注意力机制：hyperedge_atten利用Attn_head实现了对超图中超边的注意力机制，使模型能够专注于重要的超边，从而提高处理超图数据时的性能和准确度。
参数化构造：在其构造函数中，hyperedge_atten接受以下参数：nfeat: 输入特征的维度。nhid: 隐藏层的维度，也是注意力头输出的特征维度。dropout: 在注意力层后应用的dropout比率。
网络层：类内部定义了一个Attn_head实例self.intra_hpyeredge，用于计算超边内部的节点特征的加权组合，以及一个dropout层，用于防止过拟合。


lstm_model.py
定义了一个名为LSTMModel的Python类，这个类是一个基于PyTorch框架实现的神经网络模型，用于处理序列数据。这个类利用长短期记忆网络（LSTM）来捕获序列中的长期依赖关系。


data_loader.py
这份代码为加载和处理数据的一个完整的流程，从原始时间序列数据的读取开始，经过预处理和转换，最终准备好用于深度学习模型的训练和测试的数据集。
主要组件和步骤
数据读取与预处理：
使用Pandas读取CSV文件，处理日期，并按照Drug_ID和Date对数据进行排序。
将销售数据转换为对数形式，以平滑极端值，并使用MinMaxScaler进行归一化处理，以便模型更好地学习。
创建滑动窗口：
create_sliding_windows函数从一维时间序列数据中创建滑动窗口样本。
数据集划分：
根据设定的训练、验证和测试比例，将数据集分割为三部分。
reshape_and_concatenate函数用于将来自不同药品的数据重塑并合并，以构建一个统一的数据集，然后将数据重塑为适合模型输入的格式。
使用PyTorch的DataLoader和TensorDataset封装处理后的数据，创建易于迭代的数据加载器，用于模型的批量训练和测试。


load_H.py
创建了一个函数get_fund_adj_H_from_new_file，使用这个函数读取一个邻接矩阵文件'../data/A_adj(1329200).csv'，并将其转换为PyTorch张量H。用于后续的超图神经网络，作为节点和超边之间的索引


train.py
这份代码展示了工作流程，包括数据预处理、模型构建和训练、性能评估以及模型保存。结合GRU和基于注意力的图神经网络层。
主要组件
导入必要的库：使用了torch、torch.nn、pandas、numpy、sklearn.metrics等库来支持模型构建、数据处理和性能评估。
随机种子设置：为了确保实验的可重复性，代码中设置了一个随机种子。
设备选择：自动检测是否可用GPU，以便在有GPU支持的环境中加速训练过程。
模型定义：定义了两个模型，一个是基于GRU的循环神经网络模型，用于处理序列数据；另一个是基于注意力机制的超边网络层，用于增强模型对图结构数据的处理能力。
损失函数和优化器：使用均方误差损失函数（MSE）和Adam优化器。
训练过程
迭代训练：通过多个epochs迭代训练模型，每个epoch包含完整的前向传播和反向传播过程。
数据加载：使用DataLoader来批量加载训练和测试数据。
模型评估：在每10个epoch后，对模型进行评估，计算测试集上的R²分数、均方误差（MSE）和平均绝对误差（MAE）。